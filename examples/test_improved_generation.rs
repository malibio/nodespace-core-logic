use chrono::NaiveDate;
use nodespace_core_logic::{CoreLogic, NodeSpaceService};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("üß™ Testing Improved ONNX Text Generation");
    println!("========================================");

    // Initialize service
    let service = NodeSpaceService::create_with_paths(
        "/Users/malibio/nodespace/data/lance_db",
        Some("./bundled_models"),
    )
    .await?;

    // Initialize AI services
    match service.initialize().await {
        Ok(_) => println!("‚úÖ AI services initialized successfully"),
        Err(e) => {
            println!("‚ö†Ô∏è AI initialization warning: {}", e);
            println!("Continuing with test...");
        }
    }

    // Test with the query that worked well before
    let test_query = "What is the target income for campaign participants?";

    println!("\nüîç Testing Query: \"{}\"", test_query);
    println!("üéØ Expected to find: Income range 75,000-150,000 annually");

    // Execute the RAG query
    println!("\nüöÄ Executing RAG query with enhanced parameters...");
    match service.process_query(test_query).await {
        Ok(response) => {
            println!("‚úÖ RAG Query SUCCESS!");
            println!("üìä Query Execution Report:");
            println!("   ‚Ä¢ Sources found: {}", response.sources.len());
            println!("   ‚Ä¢ Confidence: {:.1}%", response.confidence * 100.0);
            println!("   ‚Ä¢ Answer: \"{}\"", response.answer);

            // Check if the answer contains the expected information
            let answer_lower = response.answer.to_lowercase();
            if answer_lower.contains("75") && answer_lower.contains("150") {
                println!("üéØ SUCCESS: Answer contains expected income range!");
            } else if answer_lower.contains("income") {
                println!("üí° PARTIAL: Answer mentions income but may not have specific range");
            } else {
                println!("‚ö†Ô∏è ISSUE: Answer doesn't seem to contain expected income information");
            }

            // Show sources for verification
            println!("\nüìö Source Analysis:");
            for (i, source) in response.sources.iter().take(3).enumerate() {
                println!("   {}. Source ID: {}", i + 1, source.as_str());
            }
        }
        Err(e) => {
            println!("‚ùå RAG Query FAILED: {}", e);
            return Err(e.into());
        }
    }

    println!("\nüî¨ ENHANCED GENERATION TEST SUMMARY:");
    println!("   ‚Ä¢ Temperature: 1.0 (increased from 0.7)");
    println!("   ‚Ä¢ Max tokens: 100 (limited for focused answers)");
    println!("   ‚Ä¢ top_p: 0.9 (hard-coded in NLP engine, team wants 0.95)");
    println!("   ‚Ä¢ Prompt format: Simplified from verbose instructions");
    println!("   ‚Ä¢ Debug logging: Enhanced tracing enabled");

    println!("\n‚úÖ Improved generation test completed!");

    Ok(())
}
